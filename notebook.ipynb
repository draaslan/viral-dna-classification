{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human and Virus DNA Classification with TensorFlow 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will classify human and viral DNA with Deep Learning using TensorFlow 2. At the end of this tutorial, our model will reach approximately 90% accuracy. But first, we need to talk about the research and some terminology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViraMiner: Deep learning on raw DNA sequences for identifying viral genomes in human samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will follow ViraMiner [paper](https://doi.org/10.1371/journal.pone.0222271) and [code](https://github.com/NeuroCSUT/ViraMiner) which is published by **Vicente R. et.al.** You can access the original article and source code. I have made some updates to the original code for educational purposes.\n",
    "\n",
    "- Updated code base from Python 2 to Python 3.\n",
    "- Added modules like pandas and removed plain Python code for I/O.\n",
    "- Used single model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The human virome is the collection of all viruses that reside in and on the human body. Correlative evidence suggesting that viruses may be involved in the development of autoimmune diseases such as diabetes and multiple sclerosis. \n",
    "\n",
    "**Next Generation Sequencing (NGS)** technologies provide a powerful tool to obtain directly the DNA sequences present in clinical samples without any prior knowledge of the biospecimens. The term metagenomics implies complete sequencing and recovering of all non-human genetic material that might be present in a human sample.\n",
    "\n",
    "**BLAST and HMMER3** are commonly used algorithms for viral discovery in metagenomic samples. Machine Learning is also a different approach. A different approaches consist of using machine learning techniques to learn from examples to classify viral genomes. **(Vicente R. et.al.)**\n",
    "\n",
    "We will use Convolutional Neural Networks (CNN) on raw metagenomic contigs to identify potential viral sequences across different human samples in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We will use [ViraMiner](https://github.com/NeuroCSUT/ViraMiner) dataset and model in this notebook.\n",
    "\n",
    "### How this DNA data collected and cleaned?\n",
    "DNA data collected from 19 different experiments and sequenced from different human sample types (serum, skin, condylomata). These contigs were combined, shuffled, and partitioned into training (80%), validation (10%), and testing (10%) sets. \n",
    "\n",
    "The metagenomic sequences in this dataset were generated using Next Generation Sequencing platforms such as the NextSeq, Miseq, and HiSeq. Derived from human samples belonging to different patient groups.\n",
    "\n",
    "All the sequencing experiments were processed and analyzed using a benchmarked bioinformatics workflow. Analysis with quality checking where reads are filtered based on their Phred quality score. Quality checked reads that align to human, bacterial, phage and vector DNA with >95% identity. Over 75% of their length are subtracted from further analysis using BWA-MEM. The reads that are left are normalized and then assembled using the IDBA-UD, Trinity, SOAPdenovo, and SOAPdenovo- Trans assemblers. The assembled contigs are then subjected to taxonomic classification using BLAST. \n",
    "\n",
    "This dataset included 19 different NGS experiments that were analyzed and labeled by PCJ-BLAST. Labeled sequences were divided into equal pieces (300bp), each one of them was labeled as the original sequence and remaining nucleotides at the end of the contigs were removed. All contigs that contained even one “N” letter (reference to any nucleotide) were removed. **(Vicente R. et.al.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset\n",
    "I simplified the ViraMiner dataset for this notebook. You can download simplified dataset from **dataset** folder.\n",
    "\n",
    "Dataset folder contains 3 csv files: **train.csv, validation.csv and test.csv**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the full path of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/aaslan/Code/ML/viral-dna-classification/dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use **pandas** package to reading csv files and processing DataFrames. Pandas supplies many functions to sorting, filtering and clearing the dataset. To further information, you can look at documentation of pandas from [here](https://pandas.pydata.org/). \n",
    "\n",
    "We import **numpy** package also. *NumPy is the fundamental package for scientific computing with Python.* It provides working with N-dimensional arrays easily and fast. We will use numpy package in upcoming lines.\n",
    "\n",
    "We import pandas firstly. Then we read csv files by **read_csv** function and assign it to the **train_set** variable with pandas. We read other sets also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_set = pd.read_csv(dataset_path + \"train.csv\")\n",
    "validation_set = pd.read_csv(dataset_path + \"validation.csv\")\n",
    "test_set = pd.read_csv(dataset_path + \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our training set looks like with **head()** attribute.\n",
    "\n",
    "First column is **DNA sequences** with 300bp length, second column is a **label** of this sequence. If DNA sequence is belongs to human it is labelled as **0** and also vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAAGCCAAGATTTTCTCGCGTCACACTACTCATGACCATTGTATTA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AACGAAGCACGGGCCGAGAGATTGAGGAACCAAGGTCCAGCTCTAG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TAGTGGGTGAGGTTTCTATTTCCATAATGATCTCGCCTCAATTACT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATATGACCATTCTTGCAAGGTAACACAGGTACATTTTCACAAAGTG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GGTCTTAAAACAACAGAAATTTTTTCCATCACAGTTGCAGAAATTA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   1  2\n",
       "0  CAAGCCAAGATTTTCTCGCGTCACACTACTCATGACCATTGTATTA...  0\n",
       "1  AACGAAGCACGGGCCGAGAGATTGAGGAACCAAGGTCCAGCTCTAG...  0\n",
       "2  TAGTGGGTGAGGTTTCTATTTCCATAATGATCTCGCCTCAATTACT...  0\n",
       "3  ATATGACCATTCTTGCAAGGTAACACAGGTACATTTTCACAAAGTG...  0\n",
       "4  GGTCTTAAAACAACAGAAATTTTTTCCATCACAGTTGCAGAAATTA...  0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**info()** attribute summarizes our training set. You can show that there are **211239** lines in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 211239 entries, 0 to 211238\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   1       211239 non-null  object\n",
      " 1   2       211239 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configurations & Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are some of the hyperparameters and configurations of our model. We will use them in our model. To configure and tune our model easily, we define them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4 #128\n",
    "learning_rate = 0.0001\n",
    "epochs = 10\n",
    "dropout = 0.1\n",
    "lr_decay = True\n",
    "train_steps_per_epoch = train_set.shape[0] // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our learning decay calculation and updating function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_decay_per_epoch(epoch):\n",
    "    initial_lrate = learning_rate\n",
    "    drop = 0.5\n",
    "    epochs_drop = 5.0\n",
    "    lrate = initial_lrate * np.power(drop,int((1+epoch)/epochs_drop))\n",
    "    lrate = np.max([initial_lrate/100,lrate])\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our helper function to convert DNA sequence to one hot encoding. Takes dataset as an input and return one encoded sequences and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNA_to_onehot(dataset):\n",
    "    options_onehot = {'A': [1,0,0,0,0],'C' :[0,1,0,0,0], 'G':[0,0,1,0,0] ,'T':[0,0,0,1,0],'N':[0,0,0,0,1]}\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for index, row in dataset.iterrows():\n",
    "        sequences.append(list(map(lambda e: options_onehot[e], row[0])))\n",
    "        labels.append(row[1])\n",
    "    sequences = sequences\n",
    "    return np.array(sequences), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will generate our training batches according to our configurations which we defined above. This generator will feed our neural network step by step because our training set is too big to store whole dataset in the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(dataset, batch_size):\n",
    "    train_steps_per_epoch = dataset.shape[0] // batch_size\n",
    "\n",
    "    while 1:\n",
    "        for i in range(0, train_steps_per_epoch):\n",
    "\n",
    "            seqs, labels = DNA_to_onehot(dataset.iloc[i*batch_size:(i+1)*batch_size,:])\n",
    "\n",
    "            yield seqs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation set is smaller than training set. So, we can store whole validation set in one time. We can use generators in validation set like training set, but we don't need that.\n",
    "\n",
    "We store validation sequences and labels in different variables: **val_seqs** and **val_labels**. We use DNA_to_onehot function which we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_seqs, val_labels = DNA_to_onehot(validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary modules from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, concatenate, Dropout\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D,GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, SGD\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most important part. In this lines we create our model's layers, activations and optimizers. We are using ViraMiner model as a base model also. Let's visualize how our model looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ViraMiner Model Structure](https://pymed.ai/images/uploads/viraminer-model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model contains **two convolutional branches** that contribute different types of information to the final fully-connected decision-making layer. \n",
    "A convolutional layer followed by average operator provides important information about the frequency of patterns. In such a case, while losing information about the maximal activation (best match), we gain information about frequency—the average cannot be high if only a few good matches were found.\n",
    "We combine feature maps processed by averaging and by max operators. This allows the model to base its decisions on both pattern-matching and pattern-frequency information. **(Vicente R. et.al.)**\n",
    "\n",
    "In original ViraMiner article, authors trained frequency and pattern branches separately. But here we train them once because of educational purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input layer shape is 300x5. 300 is length of sequence and 5 is one hot encoded form of **ACTGN** nucleotides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(300,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a frequency layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_freq = Conv1D(1000,8, activation=\"relu\")(inputs)\n",
    "freq_pooling = GlobalAveragePooling1D()(first_freq)\n",
    "drop_freq = Dropout(dropout)(freq_pooling)\n",
    "fc_layer1 = Dense(1000, activation=\"relu\", name=\"fc_layer1\")(drop_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pattern layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pattern = Conv1D(1200,11, activation=\"relu\")(inputs)\n",
    "pattern_pooling = GlobalMaxPooling1D()(first_pattern)\n",
    "drop_pattern = Dropout(dropout)(pattern_pooling)\n",
    "fc_layer2 = Dense(1200, activation=\"relu\", name=\"fc_layer2\")(drop_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenation of frequency and pattern layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenation = concatenate([fc_layer1, fc_layer2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout applied to concatenation layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_fc = Dropout(dropout, name=\"drop_fc1\")(concatenation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = Dense(1, activation=\"sigmoid\")(drop_fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our model variable input to output and compile it. We use adam optimizer and binary crossentropy as a loss function. After that, we summarize model structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300, 5)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 293, 1000)    41000       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 290, 1200)    67200       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 1000)         0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 1200)         0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1000)         0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1200)         0           global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fc_layer1 (Dense)               (None, 1000)         1001000     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "fc_layer2 (Dense)               (None, 1200)         1441200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2200)         0           fc_layer1[0][0]                  \n",
      "                                                                 fc_layer2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "drop_fc1 (Dropout)              (None, 2200)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2201        drop_fc1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,552,601\n",
      "Trainable params: 2,552,601\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs, final)\n",
    "model.compile(optimizer = Adam(lr=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save only best model with **ModelCheckpoint** callback. It will save model only which has minimum validation loss value. Also **EarlyStopping** will be activated if validation loss does not decrease 5 times in a row. Lastly, we appended **LearningRateScheduler** to decrease learning rate after some epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[]\n",
    "callbacks.append(ModelCheckpoint(filepath=\"best.h5\", verbose=1, save_best_only=True, monitor='val_loss'))\n",
    "callbacks.append(EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5))\n",
    "\n",
    "if lr_decay == True:\n",
    "    callbacks.append(LearningRateScheduler(lr_decay_per_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to fit our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "52804/52809 [============================>.] - ETA: 0s - loss: 0.0941 - accuracy: 0.9788\n",
      "Epoch 00001: val_loss improved from inf to 0.08238, saving model to best.h5\n",
      "52809/52809 [==============================] - 150s 3ms/step - loss: 0.0941 - accuracy: 0.9788 - val_loss: 0.0824 - val_accuracy: 0.9798 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "52804/52809 [============================>.] - ETA: 0s - loss: 0.0833 - accuracy: 0.9789\n",
      "Epoch 00002: val_loss improved from 0.08238 to 0.07816, saving model to best.h5\n",
      "52809/52809 [==============================] - 148s 3ms/step - loss: 0.0833 - accuracy: 0.9789 - val_loss: 0.0782 - val_accuracy: 0.9798 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "52790/52809 [============================>.] - ETA: 0s - loss: 0.0787 - accuracy: 0.9790\n",
      "Epoch 00003: val_loss improved from 0.07816 to 0.07646, saving model to best.h5\n",
      "52809/52809 [==============================] - 145s 3ms/step - loss: 0.0787 - accuracy: 0.9790 - val_loss: 0.0765 - val_accuracy: 0.9800 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "52795/52809 [============================>.] - ETA: 0s - loss: 0.0755 - accuracy: 0.9795\n",
      "Epoch 00004: val_loss improved from 0.07646 to 0.07526, saving model to best.h5\n",
      "52809/52809 [==============================] - 145s 3ms/step - loss: 0.0755 - accuracy: 0.9795 - val_loss: 0.0753 - val_accuracy: 0.9809 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "52792/52809 [============================>.] - ETA: 0s - loss: 0.0712 - accuracy: 0.9802\n",
      "Epoch 00005: val_loss did not improve from 0.07526\n",
      "52809/52809 [==============================] - 145s 3ms/step - loss: 0.0712 - accuracy: 0.9802 - val_loss: 0.0753 - val_accuracy: 0.9814 - lr: 5.0000e-05\n",
      "Epoch 6/10\n",
      "52806/52809 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 0.9806\n",
      "Epoch 00006: val_loss improved from 0.07526 to 0.07447, saving model to best.h5\n",
      "52809/52809 [==============================] - 144s 3ms/step - loss: 0.0701 - accuracy: 0.9806 - val_loss: 0.0745 - val_accuracy: 0.9815 - lr: 5.0000e-05\n",
      "Epoch 7/10\n",
      "52802/52809 [============================>.] - ETA: 0s - loss: 0.0694 - accuracy: 0.9808\n",
      "Epoch 00007: val_loss improved from 0.07447 to 0.07442, saving model to best.h5\n",
      "52809/52809 [==============================] - 145s 3ms/step - loss: 0.0694 - accuracy: 0.9808 - val_loss: 0.0744 - val_accuracy: 0.9815 - lr: 5.0000e-05\n",
      "Epoch 8/10\n",
      "52793/52809 [============================>.] - ETA: 0s - loss: 0.0689 - accuracy: 0.9808\n",
      "Epoch 00008: val_loss improved from 0.07442 to 0.07386, saving model to best.h5\n",
      "52809/52809 [==============================] - 145s 3ms/step - loss: 0.0688 - accuracy: 0.9808 - val_loss: 0.0739 - val_accuracy: 0.9815 - lr: 5.0000e-05\n",
      "Epoch 9/10\n",
      "52792/52809 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 0.9810\n",
      "Epoch 00009: val_loss did not improve from 0.07386\n",
      "52809/52809 [==============================] - 145s 3ms/step - loss: 0.0686 - accuracy: 0.9810 - val_loss: 0.0744 - val_accuracy: 0.9819 - lr: 5.0000e-05\n",
      "Epoch 10/10\n",
      "52796/52809 [============================>.] - ETA: 0s - loss: 0.0663 - accuracy: 0.9814\n",
      "Epoch 00010: val_loss did not improve from 0.07386\n",
      "52809/52809 [==============================] - 144s 3ms/step - loss: 0.0663 - accuracy: 0.9814 - val_loss: 0.0741 - val_accuracy: 0.9821 - lr: 2.5000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efcdc796be0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(generate_batches(train_set, batch_size),\n",
    "        steps_per_epoch = train_steps_per_epoch, \n",
    "        epochs = epochs, workers = 1, \n",
    "        use_multiprocessing = True, verbose = 1,  callbacks = callbacks,\n",
    "        validation_data=(np.array(val_seqs), val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing evaluation and ploting modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert test sequences to one hot encodings as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seqs, test_labels = DNA_to_onehot(test_set)\n",
    "test_steps_per_epoch = test_set.shape[0] // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load best model from file which we saved before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"best.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction of test set with our model. Last line calculates auroc score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-47-d3ac69fce067>:1: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8925676038994342"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probas = model.predict_generator(generate_batches(test_set, batch_size), \n",
    "                                      steps=test_steps_per_epoch + 1)\n",
    "pred_probas = pred_probas[:len(test_labels),:]\n",
    "roc_auc_score(test_labels, pred_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating false-postive and true-positive values for ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(test_labels, pred_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZmklEQVR4nO3debAdZZnH8e+PQARZgpjgYMI1VwxgKFkvBFAcFsWAMJEBWdUCtWJkUctlYMABBxRxoBxBwEzEiCgQlTViIOKMEBQJYQnZMNSdRMKFUKzFqgOBZ/7ovnA4Offcvjenz9L9+1SdOqe739Pn6dxUP/2+b/f7KiIwM7PyWq/VAZiZWWs5EZiZlZwTgZlZyTkRmJmVnBOBmVnJrd/qAIZq9OjRMX78+FaHYWbWUe69996nImJMrW0dlwjGjx/PPffc0+owzMw6iqSHB9rmpiEzs5JzIjAzKzknAjOzknMiMDMrOScCM7OSyy0RSJop6QlJSwbYLkkXSeqVtEjSrnnFYmZmA8uzRnA5MLnO9oOACelrKvCjHGMxM7MB5PYcQUTMkzS+TpEpwBWRjIN9l6TNJW0VEavzisnMWuuq+au4ceGjrQ6jY01892acdegODd9vKx8oGws8UrHcl65bKxFImkpSa6Crq6spwZnZwIZ7Qp+/8hkAJnVv0eiQbB20MhGoxrqas+RExAxgBkBPT49n0rHSa/WV9XBP6JO6t2DKzmM5dpIv6NpJKxNBH7B1xfI44LEWxWLWEp16Ze0TerG0MhHMBk6WNAuYBDzn/gEruuoTv6+srR3klggkXQ3sC4yW1AecBWwAEBHTgTnAwUAv8DJwQl6xmOUt65V99YnfJ3RrB3neNXTMINsDOCmv3zfL03Cv7H3it3bUccNQm7XaVfNXcfr1iwFf2VsxOBGYZVBZA+i/+j/3sA/4xG+F4ERgNoBaJ/9J3Vv46t8Kx4nArEp/AvDJ38rCicBKZ7A7fCoTgE/+VgZOBFYKAzXz1OIEYGXjRGClcOPCR1m2+nkmbrWZT/RmVZwIrJCqm3/6k8Avv7BXC6Mya09OBNbxarX5Vzf/TNxqM6bsPLbpsZl1AicC6xgDdfLWavN3849Zdk4E1vZq3c5ZySd9s3XjRGBtq1YC8AnfrPGcCKytDHSbpxOAWX6cCKyl6o3i6QRg1hxOBNY0We7u8cnfrPmcCCwXWU76/Z994jdrLScCa6h6d/j4pG/WnpwIrCF8h49Z53IisHVWPWOXE4BZZ3EisGGrrgV4xi6zzuREYMPiWoBZcTgR2JC4FmBWPE4ElplrAWbF5ERgg3ItwKzYnAisLtcCzIrPicAGVJkEXAswK671Wh2AtScnAbPycI3AgIFHAXUSMCs+J4KSG2hsIPcHmJWHE0FJeWwgM+vnRFAinv3LzGrJNRFImgxcCIwALouI86q2jwJ+AXSlsVwQET/NM6YyqnX17wRgZv1ySwSSRgCXAB8F+oAFkmZHxLKKYicByyLiUEljgOWSroyIV/KKq0zc/GNmWeRZI9gD6I2IFQCSZgFTgMpEEMCmkgRsAjwDrMkxpsJz84+ZDVWeiWAs8EjFch8wqarMxcBs4DFgU+CoiHi9ekeSpgJTAbq6fDKrxc0/ZjZceSYC1VgXVcsfAxYC+wPbALdKuiMinn/LlyJmADMAenp6qvdRWr76N7NGyDMR9AFbVyyPI7nyr3QCcF5EBNAraSWwPXB3jnEVQvUYQE4AZjZceSaCBcAESd3Ao8DRwLFVZVYBBwB3SHoXsB2wIseYOp5HAjWzRsstEUTEGkknA3NJbh+dGRFLJU1Lt08HzgEul7SYpCnp1Ih4Kq+YOp1HAjWzPOT6HEFEzAHmVK2bXvH5MeDAPGMoCg8CZ2Z58eijHcBJwMzy5ETQ5pwEzCxvTgRtrv/2UCcBM8uLB51rU/13By1b/TyTurdwEjCz3DgRtKFadweZmeXFiaANuTnIzJrJfQRt5qr5q5i/8hk3B5lZ07hG0Caqnxh2c5CZNYsTQZuo7Bj2E8Nm1kxOBG2gsjnol1/Yq9XhmFnJZO4jkLRxnoGUVeUdQm4OMrNWGDQRSNpb0jLgwXR5J0mX5h5ZCfipYTNrB1lqBP9JMoHM0wAR8QDw4TyDKgMnATNrF5mahiLikapVr+UQS6n4WQEzaxdZOosfkbQ3EJJGAl8ibSay4fGzAmbWTrLUCKYBJ5FMRt8H7AycmGNMhddfG3DnsJm1gyw1gu0i4rjKFZI+CPwpn5DKwbUBM2sXWWoEP8y4zjLobxYyM2sXA9YIJO0F7A2MkfTVik2bkcxBbEPkZwbMrB3VaxoaCWySltm0Yv3zwBF5BlVEvl3UzNrVgIkgIm4Hbpd0eUQ83MSYCsdJwMzaWZbO4pclnQ/sAGzYvzIi9s8tqoLxMwNm1s6ydBZfCfwF6Ab+HfgrsCDHmArJdwmZWbvKkgjeGRE/AV6NiNsj4rPAnjnHVRi+S8jM2l2WpqFX0/fVkj4OPAaMyy+kYvBEM2bWKbIkgm9LGgV8jeT5gc2Ar+QZVKerNfm8m4XMrF0Nmggi4qb043PAfvDGk8U2AHcOm1knqfdA2QjgSJIxhm6JiCWSDgFOBzYCdmlOiJ3FA8qZWaepVyP4CbA1cDdwkaSHgb2A0yLihibE1nH85LCZdaJ6iaAH2DEiXpe0IfAU8L6IeLw5oXUWPzRmZp2q3u2jr0TE6wAR8XfgoaEmAUmTJS2X1CvptAHK7CtpoaSlkm4fyv7bifsFzKxT1asRbC9pUfpZwDbpsoCIiB3r7TjtY7gE+CjJPAYLJM2OiGUVZTYHLgUmR8QqSVsO/1Bax/0CZtbJ6iWC96/jvvcAeiNiBYCkWcAUYFlFmWOB6yJiFUBEPLGOv9kSnmjGzDpZvUHn1nWgubFA5VzHfcCkqjLbAhtIuo1khNMLI+KK6h1JmgpMBejqaq8rbtcGzKzTZZq8fphUY11ULa8P7AZ8HPgY8G+Stl3rSxEzIqInInrGjBnT+EiHyXcJmVkRZHmyeLj6SG4/7TeOZHiK6jJPRcRLwEuS5gE7AQ/lGFdD+C4hMyuKTDUCSRtJ2m6I+14ATJDULWkkcDQwu6rMjcA+ktaX9HaSpqMHh/g7LeG7hMysKAZNBJIOBRYCt6TLO0uqPqGvJSLWACcDc0lO7r+KiKWSpkmalpZ5MN3vIpIH1y6LiCXDPJamcb+AmRVJlqahb5HcAXQbQEQslDQ+y84jYg4wp2rd9Krl84Hzs+yvHbhfwMyKJkvT0JqIeC73SDqEm4TMrGiy1AiWSDoWGCFpAvAl4M58w2pPbhIysyLKUiM4hWS+4v8DriIZjvorOcbUtvzgmJkVUZYawXYRcQZwRt7BtDPXBsysqLLUCL4v6S+SzpG0Q+4RtSF3EJtZkQ2aCCJiP2Bf4ElghqTFkr6Zd2DtxB3EZlZkmR4oi4jHI+IiYBrJMwVn5hlUO3GTkJkVXZYHyt4v6VuSlgAXk9wxNC73yNqEO4jNrOiydBb/FLgaODAiqscKKjTXBsysDAZNBBGxZzMCaUeuDZhZGQyYCCT9KiKOlLSYtw4fnWmGsqJwbcDMiq5ejeDL6fshzQik3VQ2C5mZFdmAncURsTr9eGJEPFz5Ak5sTnit42YhMyuLLLePfrTGuoMaHUg7crOQmZXBgIlA0hfT/oHtJC2qeK0kmT+gsPqbhczMyqBeH8FVwM3Ad4HTKta/EBGFPUt6OAkzK5t6iSAi4q+STqreIGmLoiYDDydhZmUzWI3gEOBekttHVbEtgPfmGFdLuW/AzMpkwEQQEYek793NC8fMzJoty1hDH5S0cfr5U5K+L8mXy2ZmBZHl9tEfAS9L2gn4F+Bh4Oe5RtUivlvIzMoo6+T1AUwBLoyIC4FN8w2rNfwQmZmVUZbRR1+Q9K/Ap4F9JI0ANsg3rNZxR7GZlU2WGsFRJBPXfzYiHgfGAufnGlULuFnIzMoqy1SVjwNXAqMkHQL8PSKuyD2yJnOzkJmVVZa7ho4E7gY+CRwJzJd0RN6BtYKbhcysjLL0EZwB7B4RTwBIGgP8Hrgmz8DMzKw5svQRrNefBFJPZ/xex3D/gJmVWZYawS2S5pLMWwxJ5/Gc/EJqPvcPmFmZZZmz+BuS/hn4EMl4QzMi4vrcI2sy9w+YWVnVm7N4AnABsA2wGPh6RDzarMDMzKw56rX1zwRuAg4nGYH0h0PduaTJkpZL6pV0Wp1yu0t6rRV3I7l/wMzKrl7T0KYR8eP083JJ9w1lx+kTyJeQTHXZByyQNDsiltUo9z1g7lD23yjuHzCzsquXCDaUtAtvzkOwUeVyRAyWGPYAeiNiBYCkWSTjFS2rKncKcC2w+xBjbxj3D5hZmdVLBKuB71csP16xHMD+g+x7LPBIxXIfMKmygKSxwGHpvgZMBJKmAlMBurp8wjYza6R6E9Pst477Vo11UbX8A+DUiHhNqlX8jVhmADMAenp6qvdhZmbrIMtzBMPVB2xdsTwOeKyqTA8wK00Co4GDJa2JiBtyjMvMzCrk+YTwAmCCpG5JI4GjgdmVBSKiOyLGR8R4kiErTmxmEvAdQ2ZmOdYIImKNpJNJ7gYaAcyMiKWSpqXbp+f121n5jiEzswyJQEm7zXHAeyPi7HS+4n+IiLsH+25EzKFqOIqBEkBEHJ8p4gbzHUNmVnZZmoYuBfYCjkmXXyB5PsDMzAogS9PQpIjYVdL9ABHxbNrmb2ZmBZClRvBq+vRvwBvzEbyea1RN4I5iM7NElkRwEXA9sKWk7wB/BM7NNaomcEexmVkiyzDUV0q6FziA5CGxT0TEg7lH1gTuKDYzy3bXUBfwMvCbynURsSrPwMzMrDmydBb/lqR/QMCGQDewHNghx7jMzKxJBu0jiIgPRMSO6fsEklFF/5h/aPlxR7GZ2ZuGPMREOvx0y4aMbgR3FJuZvSlLH8FXKxbXA3YFnswtoiZxR7GZWSJLH8GmFZ/XkPQZXJtPOGZm1mx1E0H6INkmEfGNJsVjZmZNNmAfgaT1I+I1kqagwnBHsZnZW9WrEdxNkgQWSpoN/Bp4qX9jRFyXc2y5cEexmdlbZekj2AJ4mmRe4f7nCQLoyEQA7ig2M6tULxFsmd4xtIQ3E0A/zxtsZlYQ9RLBCGATsk1Cb2ZmHapeIlgdEWc3LRIzM2uJek8W16oJmJlZwdRLBAc0LQozM2uZARNBRPhmezOzEhjyoHNmZlYsTgRmZiXnRGBmVnJOBGZmJVeqROAB58zM1laqROAB58zM1laqRAAecM7MrFrpEoGZmb2VE4GZWcnlmggkTZa0XFKvpNNqbD9O0qL0daeknfKMx8zM1pZbIkjnO74EOAiYCBwjaWJVsZXAP0bEjsA5wIy84jEzs9ryrBHsAfRGxIqIeAWYBUypLBARd0bEs+niXcC4HOMxM7Ma8kwEY4FHKpb70nUD+Rxwc60NkqZKukfSPU8++WQDQzQzszwTQeaZzSTtR5IITq21PSJmRERPRPSMGTOmgSGamVmWyeuHqw/YumJ5HPBYdSFJOwKXAQdFxNM5xmNmZjXkWSNYAEyQ1C1pJHA0MLuygKQu4Drg0xHxUI6xmJnZAHKrEUTEGkknA3OBEcDMiFgqaVq6fTpwJvBO4FJJAGsioievmMzMbG15Ng0REXOAOVXrpld8/jzw+TxjMDOz+vxksZlZyTkRmJmVnBOBmVnJORGYmZWcE4GZWck5EZiZlZwTgZlZyTkRmJmVnBOBmVnJORGYmZWcE4GZWck5EZiZlZwTgZlZyTkRmJmVnBOBmVnJORGYmZWcE4GZWck5EZiZlZwTgZlZyZUmEVw1fxXzVz7T6jDMzNpOaRLBjQsfBWDKzmNbHImZWXspTSIAmNS9BcdO6mp1GGZmbaVUicDMzNbmRGBmVnJOBGZmJedEYGZWck4EZmYl50RgZlZyTgRmZiXnRGBmVnJOBGZmJZdrIpA0WdJySb2STquxXZIuSrcvkrRrnvGYmdnacksEkkYAlwAHAROBYyRNrCp2EDAhfU0FfpRXPGZmVlueNYI9gN6IWBERrwCzgClVZaYAV0TiLmBzSVvlGJOZmVVZP8d9jwUeqVjuAyZlKDMWWF1ZSNJUkhoDXV3DGzRu4rs3G9b3zMyKLs9EoBrrYhhliIgZwAyAnp6etbZncdahOwzna2ZmhZdn01AfsHXF8jjgsWGUMTOzHOWZCBYAEyR1SxoJHA3MriozG/hMevfQnsBzEbG6ekdmZpaf3JqGImKNpJOBucAIYGZELJU0Ld0+HZgDHAz0Ai8DJ+QVj5mZ1ZZnHwERMYfkZF+5bnrF5wBOyjMGMzOrz08Wm5mVnBOBmVnJORGYmZWcE4GZWckp6a/tHJKeBB4e5tdHA081MJxO4GMuBx9zOazLMb8nIsbU2tBxiWBdSLonInpaHUcz+ZjLwcdcDnkds5uGzMxKzonAzKzkypYIZrQ6gBbwMZeDj7kccjnmUvURmJnZ2spWIzAzsypOBGZmJVfIRCBpsqTlknolnVZjuyRdlG5fJGnXVsTZSBmO+bj0WBdJulPSTq2Is5EGO+aKcrtLek3SEc2MLw9ZjlnSvpIWSloq6fZmx9hoGf5vj5L0G0kPpMfc0aMYS5op6QlJSwbY3vjzV0QU6kUy5PX/Au8FRgIPABOryhwM3EwyQ9qewPxWx92EY94beEf6+aAyHHNFuf8hGQX3iFbH3YS/8+bAMqArXd6y1XE34ZhPB76Xfh4DPAOMbHXs63DMHwZ2BZYMsL3h568i1gj2AHojYkVEvALMAqZUlZkCXBGJu4DNJW3V7EAbaNBjjog7I+LZdPEuktngOlmWvzPAKcC1wBPNDC4nWY75WOC6iFgFEBGdftxZjjmATSUJ2IQkEaxpbpiNExHzSI5hIA0/fxUxEYwFHqlY7kvXDbVMJxnq8XyO5Iqikw16zJLGAocB0ymGLH/nbYF3SLpN0r2SPtO06PKR5ZgvBt5PMs3tYuDLEfF6c8JriYafv3KdmKZFVGNd9T2yWcp0kszHI2k/kkTwoVwjyl+WY/4BcGpEvJZcLHa8LMe8PrAbcACwEfBnSXdFxEN5B5eTLMf8MWAhsD+wDXCrpDsi4vmcY2uVhp+/ipgI+oCtK5bHkVwpDLVMJ8l0PJJ2BC4DDoqIp5sUW16yHHMPMCtNAqOBgyWtiYgbmhJh42X9v/1URLwEvCRpHrAT0KmJIMsxnwCcF0kDeq+klcD2wN3NCbHpGn7+KmLT0AJggqRuSSOBo4HZVWVmA59Je9/3BJ6LiNXNDrSBBj1mSV3AdcCnO/jqsNKgxxwR3RExPiLGA9cAJ3ZwEoBs/7dvBPaRtL6ktwOTgAebHGcjZTnmVSQ1ICS9C9gOWNHUKJur4eevwtUIImKNpJOBuSR3HMyMiKWSpqXbp5PcQXIw0Au8THJF0bEyHvOZwDuBS9Mr5DXRwSM3ZjzmQslyzBHxoKRbgEXA68BlEVHzNsROkPHvfA5wuaTFJM0mp0ZExw5PLelqYF9gtKQ+4CxgA8jv/OUhJszMSq6ITUNmZjYETgRmZiXnRGBmVnJOBGZmJedEYGZWck4E1pbS0UIXVrzG1yn7YgN+73JJK9Pfuk/SXsPYx2WSJqafT6/adue6xpjup//fZUk64ubmg5TfWdLBjfhtKy7fPmptSdKLEbFJo8vW2cflwE0RcY2kA4ELImLHddjfOsc02H4l/Qx4KCK+U6f88UBPRJzc6FisOFwjsI4gaRNJ/51erS+WtNZIo5K2kjSv4op5n3T9gZL+nH7315IGO0HPA96Xfver6b6WSPpKum5jSb9Nx79fIumodP1tknoknQdslMZxZbrtxfT9l5VX6GlN5HBJIySdL2mBkjHmv5Dhn+XPpIONSdpDyTwT96fv26VP4p4NHJXGclQa+8z0d+6v9e9oJdTqsbf98qvWC3iNZCCxhcD1JE/Bb5ZuG03yVGV/jfbF9P1rwBnp5xHApmnZecDG6fpTgTNr/N7lpPMVAJ8E5pMM3rYY2JhkeOOlwC7A4cCPK747Kn2/jeTq+42YKsr0x3gY8LP080iSUSQ3AqYC30zXvw24B+iuEeeLFcf3a2ByurwZsH76+SPAtenn44GLK75/LvCp9PPmJGMQbdzqv7dfrX0VbogJK4y/RcTO/QuSNgDOlfRhkqETxgLvAh6v+M4CYGZa9oaIWCjpH4GJwJ/SoTVGklxJ13K+pG8CT5KM0HoAcH0kA7gh6TpgH+AW4AJJ3yNpTrpjCMd1M3CRpLcBk4F5EfG3tDlqR705i9ooYAKwsur7G0laCIwH7gVurSj/M0kTSEai3GCA3z8Q+CdJX0+XNwS66OzxiGwdORFYpziOZPap3SLiVUl/JTmJvSEi5qWJ4uPAzyWdDzwL3BoRx2T4jW9ExDX9C5I+UqtQRDwkaTeS8V6+K+l3EXF2loOIiL9Luo1k6OSjgKv7fw44JSLmDrKLv0XEzpJGATcBJwEXkYy384eIOCztWL9tgO8LODwilmeJ18rBfQTWKUYBT6RJYD/gPdUFJL0nLfNj4Cck0/3dBXxQUn+b/9slbZvxN+cBn0i/szFJs84dkt4NvBwRvwAuSH+n2qtpzaSWWSQDhe1DMpga6fsX+78jadv0N2uKiOeALwFfT78zCng03Xx8RdEXSJrI+s0FTlFaPZK0y0C/YeXhRGCd4kqgR9I9JLWDv9Qosy+wUNL9JO34F0bEkyQnxqslLSJJDNtn+cGIuI+k7+Bukj6DyyLifuADwN1pE80ZwLdrfH0GsKi/s7jK70jmpf19JNMvQjJPxDLgPiWTlv8Xg9TY01geIBma+T9Iaid/Iuk/6PcHYGJ/ZzFJzWGDNLYl6bKVnG8fNTMrOdcIzMxKzonAzKzknAjMzErOicDMrOScCMzMSs6JwMys5JwIzMxK7v8B3ZwtVEiwyroAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc_curve(fpr,tpr): \n",
    "    plt.plot(fpr, tpr) \n",
    "    plt.xlabel('False Positive Rate') \n",
    "    plt.ylabel('True Positive Rate') \n",
    "    plt.show()\n",
    "    \n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this tutorial's default configurations, we get loss: 0.0520, acccuracy: 0.9847, validation loss: 0.0701, validation accuracy: 0.9826. Our ROC AUC score is approximately 0.897. It is little bit less than original article which is 0.923.\n",
    "\n",
    "These values can be changed train by train, but does not deviate much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We classified DNA data in this tutorial. We used ViraMiner dataset and base model to achieve this. Our dataset consists of 300bp in length sequences. These sequences gathered from different sources. In final evaluation, our model achieved 0.897 on ROC AUC score. \n",
    "\n",
    "If you want to get better results on this model you can read original ViraMiner [paper](https://doi.org/10.1371/journal.pone.0222271). Different approaches and hyperparameter available in this paper."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
